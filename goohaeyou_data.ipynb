{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPxKk2PqQBN/DH8txpB8BlV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itonse/google-colab-archive/blob/main/goohaeyou_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 도로명 주소 변환 (서울 데이터)\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# 데이터 로드\n",
        "file_path = \"/content/juso/seoul.csv\"\n",
        "data = pd.read_csv(\n",
        "    file_path,\n",
        "    encoding='cp949',\n",
        "    sep='|',\n",
        "    usecols=range(13)\n",
        ")\n",
        "\n",
        "# 열 이름 설정\n",
        "data.columns = ['id', 'code', '시도', 'eng_sido', '시군구', 'eng_sigungu', 'unused1', 'unused2',\n",
        "                'road_code', '도로명', 'eng_roadname', 'building_main_no', 'building_sub_no']\n",
        "\n",
        "# 문자열로 변환하고 NaN 값을 빈 문자열로 대체\n",
        "data = data.fillna('').astype(str)\n",
        "\n",
        "# 필요한 열 추출 및 주소 포맷팅\n",
        "def format_address(row):\n",
        "    building_sub_no = str(int(float(row['building_sub_no']))) if row['building_sub_no'] else ''\n",
        "    address_parts = [row['시도'], row['시군구'], row['도로명'], building_sub_no]\n",
        "    formatted_address = \" \".join(part for part in address_parts if part)  # 부분이 비어있지 않으면 포함\n",
        "    return formatted_address\n",
        "\n",
        "data['FormattedAddress'] = data.apply(format_address, axis=1)\n",
        "\n",
        "# 중복된 행 제거\n",
        "data.drop_duplicates(subset='FormattedAddress', keep='first', inplace=True)\n",
        "\n",
        "# 결과 데이터를 새로운 Excel 파일로 저장\n",
        "output_path = \"/content/result/seoul.xlsx\"\n",
        "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "data.to_excel(output_path, index=False, columns=['FormattedAddress'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceVBiRcsxqnE",
        "outputId": "f5e7f45e-e64b-4fb8-e794-21d78d875baa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-2421bba7f4d2>:6: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       id code     시도 eng_sido  시군구 eng_sigungu unused1 unused2  \\\n",
            "0  135965  1.0  서울특별시    Seoul  강남구  Gangnam-gu                   \n",
            "1  135964  1.0  서울특별시    Seoul  강남구  Gangnam-gu                   \n",
            "2  135964  1.0  서울특별시    Seoul  강남구  Gangnam-gu                   \n",
            "3  135965  1.0  서울특별시    Seoul  강남구  Gangnam-gu                   \n",
            "4  135962  1.0  서울특별시    Seoul  강남구  Gangnam-gu                   \n",
            "\n",
            "        road_code     도로명     eng_roadname building_main_no building_sub_no  \\\n",
            "0  116804166052.0  개포로17길  Gaepo-ro 17-gil              0.0             9.0   \n",
            "1  116804166053.0  개포로20길  Gaepo-ro 20-gil              0.0            25.0   \n",
            "2  116803121022.0     논현로      Nonhyeon-ro              0.0            88.0   \n",
            "3  116803122001.0     개포로         Gaepo-ro              0.0           251.0   \n",
            "4  116803121022.0     논현로      Nonhyeon-ro              0.0            42.0   \n",
            "\n",
            "      FormattedAddress  \n",
            "0   서울특별시 강남구 개포로17길 9  \n",
            "1  서울특별시 강남구 개포로20길 25  \n",
            "2     서울특별시 강남구 논현로 88  \n",
            "3    서울특별시 강남구 개포로 251  \n",
            "4     서울특별시 강남구 논현로 42  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 지역별 데이터를 무작위로 섞음\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 파일 경로 설정\n",
        "excel_path = 'result/location.xlsx'\n",
        "\n",
        "# 엑셀 파일 로드\n",
        "df = pd.read_excel(excel_path)\n",
        "\n",
        "# 데이터프레임의 행을 무작위로 섞음\n",
        "shuffled_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# 섞은 데이터 저장\n",
        "output_path = 'result/shuffled_location.xlsx'\n",
        "shuffled_df.to_excel(output_path, index=False)"
      ],
      "metadata": {
        "id": "dXcXgKsaOnUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## member 데이터 10만개 bulk insert문 생성\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "import string\n",
        "import nltk\n",
        "from datetime import datetime, timedelta\n",
        "from nltk.corpus import words\n",
        "\n",
        "# location 데이터 로드\n",
        "locations_df = pd.read_excel('temp/shuffled_location.xlsx')\n",
        "\n",
        "# 파일 저장 경로 설정\n",
        "output_sql_path = 'result/bulk_insert_member.sql'\n",
        "\n",
        "# NLTK 단어 목록 다운로드 및 필터\n",
        "nltk.download('words')\n",
        "word_list = words.words()\n",
        "# 영문자 단어만 필터링 후 4,5,6 자리 단어만 추출\n",
        "four_letter_words = [word for word in word_list if len(word) == 4 and word.isalpha() and word == word.lower()]\n",
        "five_letter_words = [word for word in word_list if len(word) == 5 and word.isalpha() and word == word.lower()]\n",
        "\n",
        "# 한국인 성 리스트\n",
        "korean_surnames = [\"김\", \"이\", \"박\", \"최\", \"정\", \"강\", \"조\", \"윤\", \"장\", \"임\", \"오\", \"한\", \"신\", \"서\", \"권\", \"황\", \"안\", \"송\", \"류\", \"전\"]\n",
        "\n",
        "# 남성 이름 리스트\n",
        "korean_male_given_names = [\n",
        "    \"민준\", \"서준\", \"예준\", \"도윤\", \"시우\", \"주원\", \"하준\", \"지호\", \"지후\", \"준서\",\n",
        "    \"준우\", \"현우\", \"도현\", \"지훈\", \"건우\", \"우진\", \"선우\", \"서진\", \"민재\", \"현준\"\n",
        "]\n",
        "\n",
        "# 여성 이름 리스트\n",
        "korean_female_given_names = [\n",
        "    \"서연\", \"민서\", \"지우\", \"서현\", \"민지\", \"지유\", \"지민\", \"채원\", \"수아\", \"다은\",\n",
        "    \"예은\", \"서아\", \"수민\", \"서윤\", \"지안\", \"하윤\", \"유진\", \"은서\", \"지아\", \"소율\"\n",
        "]\n",
        "\n",
        "# 지역코드 매핑\n",
        "region_code_map = {\n",
        "    \"서울\": 101,\n",
        "    \"경기\": 102,\n",
        "    \"부산\": 103,\n",
        "    \"경남\": 104,\n",
        "    \"인천\": 105,\n",
        "    \"경북\": 106,\n",
        "    \"대구\": 107,\n",
        "    \"충남\": 108,\n",
        "    \"전남\": 109,\n",
        "    \"전북특별자치도\": 110,\n",
        "    \"충북\": 111,\n",
        "    \"강원특별자치도\": 112,\n",
        "    \"대전\": 113,\n",
        "    \"광주\": 114,\n",
        "    \"울산\": 115,\n",
        "    \"제주특별자치도\": 116,\n",
        "    \"세종특별자치시\": 117\n",
        "}\n",
        "\n",
        "# 설정 및 데이터 생성\n",
        "num_samples = 100000   # 10만개 설정\n",
        "start_date = datetime(2024, 7, 30)\n",
        "end_date = datetime(2024, 7, 30)\n",
        "date_range = [start_date + timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
        "\n",
        "# 비밀번호: '11111111' 해싱\n",
        "hashed_password = '$2a$10$JMUdQsovXBtYU7FblqgyzOn6h0bE5.rzdMOMZSpuewiM1b.YCFcRm'\n",
        "\n",
        "# 유니크한 username을 저장하기 위한 집합\n",
        "username_set = set()\n",
        "\n",
        "members = []\n",
        "for i in range(num_samples):\n",
        "    id = i + 1\n",
        "    # 랜덤 created_at, modified_at 생성\n",
        "    base_date = random.choice(date_range)\n",
        "    random_time = timedelta(hours=random.randint(0, 23), minutes=random.randint(0, 59), seconds=random.randint(0, 59), microseconds=random.randint(0, 999999))\n",
        "    created_at = modified_at = (base_date + random_time).strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]\n",
        "\n",
        "    birth_year = random.randint(1964, 2004)\n",
        "    birth = f\"{birth_year}-{'%02d' % random.randint(1, 12)}-{'%02d' % random.randint(1, 28)}\"\n",
        "    gender = random.choice(['MALE', 'FEMALE'])\n",
        "    location = locations_df.iloc[i, 0]\n",
        "    surname = random.choice(korean_surnames)\n",
        "    given_name = random.choice(korean_male_given_names if gender == 'MALE' else korean_female_given_names)\n",
        "    name = surname + given_name\n",
        "    phone_number = \"010\" + ''.join(random.choices(string.digits, k=8))\n",
        "    # 지역코드 추출\n",
        "    region = location.split()[0]  # 도로명 주소에서 첫 번째 단어는 시,도\n",
        "    region_code = region_code_map.get(region, 999)\n",
        "\n",
        "    # 유니크한 랜덤 username 생성\n",
        "    while True:\n",
        "        if random.choice([True, False, False]):  # 5자리 영단어 + 2자리 숫자 (1/3 확률)\n",
        "            username = random.choice(five_letter_words) + ''.join(random.choices(string.digits, k=2))\n",
        "        elif random.choice([True, False]):  # 4자리 영단어 + 3자리 숫자 (나머지 2/3 확률 중 1/2 확률)\n",
        "            username = random.choice(four_letter_words) + ''.join(random.choices(string.digits, k=3))\n",
        "        else:  # 5자리 영단어 + 2자리 영소문자 (나머지 1/3 확률)\n",
        "            username = random.choice(five_letter_words) + ''.join(random.choices(string.ascii_lowercase, k=2))\n",
        "\n",
        "        # 중복되지 않은 경우 루프 탈출\n",
        "        if username not in username_set:\n",
        "            username_set.add(username)\n",
        "            break\n",
        "\n",
        "    # 랜덤 email 생성\n",
        "    email = username + \"@goohaeyou.com\"\n",
        "\n",
        "    member = (id, created_at, modified_at, birth, email, gender, location, name, hashed_password, phone_number, username, region_code)\n",
        "    members.append(member)\n",
        "\n",
        "# SQL 파일 생성\n",
        "with open(output_sql_path, 'w') as file:\n",
        "    file.write(\"INSERT INTO member (id, created_at, modified_at, birth, email, gender, location, name, password, phone_number, username, authenticated, rest_cash, role, transaction_count, region_code) VALUES\\n\")\n",
        "    for i, member in enumerate(members):\n",
        "        sql = f\"('{member[0]}', '{member[1]}', '{member[2]}', '{member[3]}', '{member[4]}', '{member[5]}', '{member[6]}', '{member[7]}', '{member[8]}', '{member[9]}', '{member[10]}', 1, 0, 'USER', 0, '{member[11]}')\"\n",
        "        if i < len(members) - 1:\n",
        "            sql += \",\\n\"\n",
        "        else:\n",
        "            sql += \";\\n\"\n",
        "        file.write(sql)\n"
      ],
      "metadata": {
        "id": "cGYQkD48k7jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## username 목록 생성\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# 파일 경로 설정\n",
        "input_sql_path = 'result/bulk_insert_member.sql'\n",
        "output_ids_usernames_path = 'result/ids_usernames.csv'\n",
        "\n",
        "# SQL 파일에서 id와 username 값을 추출하여 목록 생성\n",
        "ids_usernames = []\n",
        "with open(input_sql_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "    for line in lines[1:]:  # 첫 줄은 INSERT INTO statement\n",
        "        if line.strip().endswith(';'):\n",
        "            line = line.strip()[:-1]  # 마지막 세미콜론 제거\n",
        "        # 정규식을 사용하여 id와 username 추출\n",
        "        match = re.search(r\"\\('(\\d+)', '[^']*', '[^']*', '[^']*', '[^']*', '[^']*', '[^']*', '[^']*', '[^']*', '[^']*', '([^']*)'\", line)\n",
        "        if match:\n",
        "            id_value = match.group(1)\n",
        "            username_value = match.group(2)\n",
        "            ids_usernames.append((id_value, username_value))\n",
        "\n",
        "# id와 username 값을 CSV 파일로 저장\n",
        "df_ids_usernames = pd.DataFrame(ids_usernames, columns=['id', 'username'])\n",
        "df_ids_usernames.to_csv(output_ids_usernames_path, index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO7_X1xWvcfU",
        "outputId": "696646be-bfcb-4d30-b8cd-cc482c04a286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('1', 'cent990'), ('2', 'gregowx'), ('3', 'slipe59'), ('4', 'locum05'), ('5', 'sifacoi'), ('6', 'fudge77'), ('7', 'rase779'), ('8', 'fogleli'), ('9', 'heave23'), ('10', 'targefp')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## title(공고 제목), body(공고 내용) 쌍의 데이터 100만개 생성\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "def generate_dataset(num_samples):\n",
        "    job_types = [\n",
        "    # 일상 도움\n",
        "    \"강아지 산책\", \"강아지 발톱 정리\", \"고양이 귀청소\", \"햄스터 톱밥 청소\",\n",
        "    \"화분 분갈이\", \"커튼봉 설치\", \"여행계획\", \"기차 예매\", \"쇼핑 같이\",\n",
        "    \"전화 문의 대신\", \"찢어진 인형 수리\", \"그늘막 설치\", \"모루인형 만들기\",\n",
        "    \"시험장까지 픽업\", \"아이 픽업\",\n",
        "    # 정리 및 청소\n",
        "    \"정리정돈\", \"집 청소\", \"화단 청소\", \"이불 빨래\", \"베란다 창문 닦기\",\n",
        "    \"대형 폐기물 운반\", \"현수막 수거\",\n",
        "    # 물류 및 배송\n",
        "    \"배달\", \"짐 이동\", \"우편물\", \"헬스기구 운반\", \"가게에서 물건 픽업\",\n",
        "    \"터미널 수화물 픽업\", \"굿즈 대리구매\", \"팝업스토어 대리구매\", \"과일포장 작업\",\n",
        "    \"식품 포장\", \"준비물 전달\",\n",
        "    # 기술 작업\n",
        "    \"정비\", \"침대 프레임 조립\", \"시계 약 교체\", \"커튼봉 설치\", \"싱크대 수전 교체\",\n",
        "    \"워셔액 보충\", \"차량 와이퍼 교체\", \"컴퓨터 설치\", \"노트북 수리\", \"증명사진 보정\",\n",
        "    # 매장\n",
        "    \"생일선물 포장\", \"포장\", \"전단지 부착\", \"홍보물부착\",\n",
        "    # 사무 및 교육\n",
        "    \"미술학원 일일 보조 강사\", \"학원 수강생 출석 체크\", \"수업 자료 정리\",\n",
        "    # 행사\n",
        "    \"체육대회 정리\", \"스타벅스 프리퀀시 수령 오픈런\", \"이벤트 장식 설치\",\n",
        "    # 기타\n",
        "    \"단순조립\", \"헤어 모델\", \"고양이 방문 시터\", \"피아노 운반/조율\", \"유튜브 콘텐츠 촬영\",\n",
        "    \"당근마켓 지역 인증\", \"벌집 제거\"\n",
        "    ]\n",
        "    descriptors = [\n",
        "        \"단순\", \"[바로가능]\", \"오늘\", \"지금\", \"근처 사시는 분\", \"하루만\", \"[30분 소요]\",\n",
        "        \"경험자 우대!\", \"추가 모집\", \"상시\", \"내일\", \"[긴급]\", \"[협의 가능]\", \"쉬워요/\", \"[현장 지급]\",\n",
        "        \"1시간 이하/\", \"[10분컷]\"\n",
        "        ]\n",
        "    actions = [\n",
        "        \"해주실분\", \"해주세요\", \"구합니다\", \"구해요\", \"하실 분 구해요\", \"하실 분 있으신가요?\", \"도와주실 분 찾습니다\",\n",
        "        \"해주실분 찾아요\", \"도와주실 분 구해요\", \"하실 분?\"\n",
        "    ]\n",
        "    details1 = [\n",
        "        \"시간 약속 잘 지키시는 분\", \"경험 있으신 분\", \"금액 제시도 가능합니다\",\n",
        "        \"친구랑 같이 가능\", \"일찍 끝나도 약속한대로 지급\", \"성격이 밝으신 분\", \"초보자 지원하지 말아주세요\",\n",
        "        \"시간 조절 가능\", \"시간/페이 협의 가능\"\n",
        "    ]\n",
        "    details2 = [\n",
        "        \"1명만 모집합니다\", \"오래 하실 수 있는 분 좋아요\", \"자주 하실 수 있으면 좋습니다\", \"댓글로 문의 해주세요~\",\n",
        "        \"승인되시면 전화로 안내드립니다\", \"많이 지원해주세요\", \"자신 있는 분 지원하세요\",\n",
        "        \"현장에서 바로 지급합니다\", \"댓글에 질문 남겨주세요.\", \"승인 후 채팅 답장 부탁합니다.\", \"채팅으로 자세한 시간약속 잡을게요\",\n",
        "        \"장소 이동 가능하신 분이 좋습니다\", \"책임감있게 해주실 분 환영해요\"\n",
        "    ]\n",
        "\n",
        "    selected_job_types = random.choices(job_types, k=num_samples)\n",
        "\n",
        "    titles = [f\"{random.choice(descriptors)} {job_type} {random.choice(actions)}\"\n",
        "              for job_type in selected_job_types]\n",
        "    bodies = [f\"{job_type} {random.choice(details1)} \\n{random.choice(details2)}\"\n",
        "              for job_type in selected_job_types]\n",
        "\n",
        "    # 데이터셋 생성\n",
        "    data = pd.DataFrame({\n",
        "        \"title\": titles,\n",
        "        \"body\": bodies,\n",
        "    })\n",
        "\n",
        "    return data\n",
        "\n",
        "full_dataset = generate_dataset(1000000)\n",
        "\n",
        "sava_path = \"result/title_body.xlsx\"\n",
        "full_dataset.to_excel(sava_path, index=False)"
      ],
      "metadata": {
        "id": "zAFXjW0DYddl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## job_post 데이터 100만개 bulk insert문 생성\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "from datetime import datetime, date, timedelta\n",
        "\n",
        "# 파일 경로\n",
        "input_excel_title_body_path = 'result/title_body.xlsx'\n",
        "input_excel_location_path = 'temp/shuffled_location.xlsx'\n",
        "output_path = 'result/bulk_insert_job_post.sql'\n",
        "\n",
        "# 파일 로드\n",
        "title_body_df = pd.read_excel(input_excel_title_body_path)\n",
        "locations_df = pd.read_excel(input_excel_location_path)\n",
        "\n",
        "# 지역코드 매핑\n",
        "region_code_map = {\n",
        "    \"서울\": 101,\n",
        "    \"경기\": 102,\n",
        "    \"부산\": 103,\n",
        "    \"경남\": 104,\n",
        "    \"인천\": 105,\n",
        "    \"경북\": 106,\n",
        "    \"대구\": 107,\n",
        "    \"충남\": 108,\n",
        "    \"전남\": 109,\n",
        "    \"전북특별자치도\": 110,\n",
        "    \"충북\": 111,\n",
        "    \"강원특별자치도\": 112,\n",
        "    \"대전\": 113,\n",
        "    \"광주\": 114,\n",
        "    \"울산\": 115,\n",
        "    \"제주특별자치도\": 116,\n",
        "    \"세종특별자치시\": 117\n",
        "}\n",
        "\n",
        "# 랜덤 날짜 생성\n",
        "start_date = datetime(2024, 7, 30)\n",
        "end_date = datetime(2024, 8, 13)\n",
        "\n",
        "# 데이터 생성\n",
        "application_count = 0\n",
        "comments_count = 0\n",
        "increment_view_count = 0\n",
        "interests_count = 0\n",
        "closed = False\n",
        "employed = False\n",
        "\n",
        "# 데이터 개수 지정\n",
        "num_samples = 10\n",
        "\n",
        "# SQL 파일 오픈\n",
        "with open(output_path, 'w') as file:\n",
        "    # Bulk insert 시작 부분\n",
        "    file.write(\"INSERT INTO job_post (id, created_at, modified_at, application_count, closed, comments_count, deadline, employed, increment_view_count, interests_count, job_start_date, location, title, member_id, region_code) VALUES\\n\")\n",
        "\n",
        "\n",
        "    for i in range(0, num_samples):\n",
        "        random_date = start_date + timedelta(seconds=random.randint(0, int((end_date - start_date).total_seconds())))\n",
        "        created_at = random_date\n",
        "        modified_at = created_at\n",
        "        deadline = created_at + timedelta(days=7)\n",
        "        job_start_date = deadline + timedelta(days=1)\n",
        "        title = title_body_df.iloc[i, 0]\n",
        "        location = locations_df.iloc[i, 0]\n",
        "\n",
        "        # 지역코드 추출\n",
        "        region = location.split()[0]  # 도로명 주소에서 첫 번째 단어는 시,도\n",
        "        region_code = region_code_map.get(region, 999)\n",
        "\n",
        "        # member_id를 1에서 100000 사이의 무작위 값으로 설정\n",
        "        member_id = random.randint(1, 100000)\n",
        "\n",
        "        # 날짜 포맷을 2024-01-01 형식으로 변경\n",
        "        deadline_str = deadline.strftime('%Y-%m-%d')\n",
        "        job_start_date_str = job_start_date.strftime('%Y-%m-%d')\n",
        "\n",
        "        # 데이터 값을 생성\n",
        "        sql = f\"({i + 1}, '{created_at.strftime('%Y-%m-%d %H:%M:%S.%f')}', '{modified_at.strftime('%Y-%m-%d %H:%M:%S.%f')}', {application_count}, {int(closed)}, {comments_count}, '{deadline_str}', {int(employed)}, {increment_view_count}, {interests_count}, '{job_start_date_str}', '{location}', '{title}', {member_id}, {region_code})\"\n",
        "\n",
        "        # 마지막 데이터가 아니면 쉼표와 줄바꿈 추가\n",
        "        if i < num_samples - 1:\n",
        "            sql += \",\\n\"\n",
        "        else:\n",
        "            sql += \";\\n\"\n",
        "\n",
        "        file.write(sql)"
      ],
      "metadata": {
        "id": "3VZagFsSOMFJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## job_post_detail 데이터 100만개 bulk insert문 생성\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# 파일 경로\n",
        "excel_title_body_path = 'result/title_body.xlsx'\n",
        "ids_usernames_path = 'result/ids_usernames.csv'\n",
        "input_job_post_path = 'result/bulk_insert_job_post.sql'\n",
        "output_path = 'result/bulk_insert_job_post_detail.sql'\n",
        "\n",
        "# 파일 로드\n",
        "title_body_df = pd.read_excel(excel_title_body_path)\n",
        "ids_usernames_df = pd.read_csv(ids_usernames_path)\n",
        "\n",
        "# ids_usernames_df를 딕셔너리로 변환\n",
        "id_to_username = dict(zip(ids_usernames_df['id'], ids_usernames_df['username']))\n",
        "\n",
        "# bulk_insert_job_post.sql 파일에서 job_post_id, member_id, created_at 추출\n",
        "job_post_ids_members_created_at = []\n",
        "\n",
        "with open(input_job_post_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "    for line in lines:\n",
        "        match = re.match(r\"\\((\\d+),.*?, (\\d+), \\d+\\)\", line.strip())\n",
        "        if match:\n",
        "            job_post_id = int(match.group(1))\n",
        "            member_id = int(match.group(2))\n",
        "            created_at = int(match.group(3))\n",
        "            job_post_ids_members_created_at.append((job_post_id, member_id))\n",
        "\n",
        "# SQL 파일 오픈\n",
        "with open(output_path, 'w') as file:\n",
        "    # Bulk insert 시작 부분\n",
        "    file.write(\"INSERT INTO job_post_detail (id, created_at, modified_at, author, body, job_post_id) VALUES\\n\")\n",
        "\n",
        "    for i in range(len(job_post_ids_members_created_at)):\n",
        "        job_post_id, member_id, created_at = job_post_ids_members_created_at[i]\n",
        "        modified_at = created_at\n",
        "        body = title_body_df.iloc[i, 1]\n",
        "\n",
        "        # member_id에 해당하는 author 추출\n",
        "        author = id_to_username.get(member_id, 'unknown')\n",
        "\n",
        "        # 데이터 값을 생성\n",
        "        sql = f\"({i + 1}, '{created_at}', '{modified_at}', '{author}', '{body}', {job_post_id})\"\n",
        "\n",
        "        # 마지막 데이터가 아니면 쉼표와 줄바꿈 추가\n",
        "        if i < len(job_post_ids_members_created_at) - 1:\n",
        "            sql += \",\\n\"\n",
        "        else:\n",
        "            sql += \";\\n\"\n",
        "\n",
        "        file.write(sql)"
      ],
      "metadata": {
        "id": "yqscMOHUkxU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## essential 데이터 100만개 bulk insert문 생성\n",
        "\n",
        "import random\n",
        "\n",
        "# 파일 경로 설정\n",
        "output_sql_path = 'result/bulk_insert_essential.sql'\n",
        "\n",
        "# 데이터 범위 및 옵션 설정\n",
        "num_samples = 1000000\n",
        "genders = ['UNDEFINED'] * 60 + ['MALE'] * 20 + ['FEMALE'] * 20  # 무관6, 남2, 여2 비율로 설정\n",
        "age_distribution = [0] * 40 + [20] * 30 + [25] * 5 + [30] * 10 + [40] * 5  # 해당 비율로 나이 분포 설정\n",
        "\n",
        "# SQL 파일 생성\n",
        "with open(output_sql_path, 'w') as file:\n",
        "    # Bulk insert 시작 부분\n",
        "    file.write(\"INSERT INTO essential (id, gender, min_age, job_post_detail_id) VALUES\\n\")\n",
        "\n",
        "    for i in range(1, num_samples + 1):\n",
        "        gender = random.choice(genders)  # 랜덤으로 성별 선택\n",
        "        min_age = random.choice(age_distribution)  # 랜덤으로 나이 선택\n",
        "        job_post_detail_id = i  # 1부터 100만까지 순차적 증가\n",
        "\n",
        "        # 데이터 값을 생성\n",
        "        sql = f\"({i}, '{gender}', {min_age}, {job_post_detail_id})\"\n",
        "\n",
        "        # 마지막 데이터가 아니면 쉼표와 줄바꿈 추가\n",
        "        if i < num_samples:\n",
        "            sql += \",\\n\"\n",
        "        else:\n",
        "            sql += \";\\n\"\n",
        "\n",
        "        file.write(sql)"
      ],
      "metadata": {
        "id": "doQA95DS-Bj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## wage 데이터 100만개 bulk insert문 생성\n",
        "\n",
        "import random\n",
        "\n",
        "# SQL 파일에서 데이터 읽기\n",
        "def read_sql_file(file_path):\n",
        "    titles = []\n",
        "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "        for line in file:\n",
        "            if line.strip().endswith('),') or line.strip().endswith(');'):  # 데이터가 있는 행인지 확인\n",
        "                parts = line.split(',')\n",
        "                title = parts[12].strip().strip(\"'\")  # 'title' 열의 값을 추출\n",
        "                titles.append(title)\n",
        "    return titles\n",
        "\n",
        "# wage 데이터 생성\n",
        "def generate_wage(title, index):\n",
        "    day_keywords = [\"오늘\", \"지금\", \"하루만\", \"내일\", \"체육대회 정리\", \"헬스기구 운반\", \"일일\", \"그늘막 설치\"]\n",
        "    hour_keywords = [\"30분\", \"1시간\", \"10분컷\", \"시계 약 교체\", \"커튼봉 설치\", \"기차 예매\",\n",
        "                     \"강아지 발톱 정리\", \"고양이 귀청소\", \"햄스터 톱밥 청소\", \"시험장까지 픽업\"]\n",
        "\n",
        "    # pay_basis 설정\n",
        "    if any(keyword in title for keyword in day_keywords):\n",
        "        pay_basis = 'TOTAL_DAYS'\n",
        "        work_days = 1\n",
        "        work_time = 0\n",
        "    elif any(keyword in title for keyword in hour_keywords):\n",
        "        pay_basis = 'TOTAL_HOURS'\n",
        "        work_days = 1\n",
        "        work_time = 1\n",
        "    else:\n",
        "        pay_basis = random.choice(['TOTAL_HOURS'] * 70 + ['TOTAL_DAYS'] * 30)\n",
        "        if pay_basis == 'TOTAL_HOURS':\n",
        "            work_days = 1\n",
        "            work_time = random.choice([1, 2] * 70 + [3, 4, 5] * 20 + [6, 7, 8] * 10)  # 1,2는 70%, 3~5는 20%, 6~8는 10% 비율로 설정\n",
        "        else:\n",
        "            work_days = random.choice([1, 2, 3] * 70 + [4, 5] * 25 + [6, 7] * 5)  # 1~3은 70%, 4,5는 25%, 6,7은 5% 비율로 설정\n",
        "            work_time = 0\n",
        "\n",
        "    # cost 설정\n",
        "    if pay_basis == 'TOTAL_HOURS':\n",
        "        if work_time in [1, 2]:\n",
        "            cost = random.choice(range(10000, 35000, 5000))  # 10000에서 30000까지, 5000 단위\n",
        "        elif work_time in [3, 4, 5]:\n",
        "            cost = random.choice(range(20000, 45000, 5000))  # 20000에서 40000까지, 5000 단위\n",
        "        else:\n",
        "            cost = random.choice(range(40000, 65000, 5000))  # 40000에서 60000까지, 5000 단위\n",
        "    else:\n",
        "        if work_days in [1, 2, 3]:\n",
        "            cost = random.choice(range(20000, 45000, 5000))  # 20000에서 40000까지, 5000 단위\n",
        "        elif work_days in [4, 5]:\n",
        "            cost = random.choice(range(30000, 65000, 5000))  # 30000에서 60000까지, 5000 단위\n",
        "        else:\n",
        "            cost = random.choice(range(40000, 95000, 5000))  # 40000에서 90000까지, 5000 단위\n",
        "\n",
        "    wage_payment_method = random.choice(['INDIVIDUAL_PAYMENT', 'SERVICE_PAYMENT'])\n",
        "    paid = 0  # 모두 false니까 0으로 설정\n",
        "\n",
        "    return f\"({index + 1}, {cost}, {paid}, '{pay_basis}', '{wage_payment_method}', {work_days}, {work_time}, {index + 1}),\\n\"\n",
        "\n",
        "# SQL 파일 쓰기\n",
        "def write_to_sql_file(titles, output_file):\n",
        "    with open(output_file, 'w', encoding='utf-8') as file:\n",
        "        file.write(\"INSERT INTO wage (id, cost, paid, pay_basis, wage_payment_method, work_days, work_time, job_post_detail) VALUES\\n\")\n",
        "        for index, title in enumerate(titles):\n",
        "            sql_statement = generate_wage(title, index)\n",
        "            if index < len(titles) - 1:\n",
        "                file.write(sql_statement)\n",
        "            else:\n",
        "                # 마지막 행 처리\n",
        "                file.write(sql_statement[:-2] + \";\\n\")\n",
        "\n",
        "# 파일 경로 설정\n",
        "input_file_path = 'result/bulk_insert_job_post.sql'\n",
        "output_file_path = 'result/bulk_insert_wage.sql'\n",
        "\n",
        "# 파일 읽고 쓰기\n",
        "job_post_titles = read_sql_file(input_file_path)\n",
        "write_to_sql_file(job_post_titles, output_file_path)"
      ],
      "metadata": {
        "id": "jfHucmwRsT8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## job_post_category 데이터 200만개 bulk insert문 생성\n",
        "\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "# 카테고리 데이터 정의\n",
        "category_data = [\n",
        "    (1, True, 1, '업무', None, 'TASK'),\n",
        "    (2, True, 1, '지역', None, 'REGION'),\n",
        "    (3, True, 2, '일상 도움', 1, 'TASK'),\n",
        "    (4, True, 2, '정리 및 청소', 1, 'TASK'),\n",
        "    (5, True, 2, '물류 및 배송', 1, 'TASK'),\n",
        "    (6, True, 2, '기술 작업', 1, 'TASK'),\n",
        "    (7, True, 2, '매장', 1, 'TASK'),\n",
        "    (8, True, 2, '사무 및 교육', 1, 'TASK'),\n",
        "    (9, True, 2, '행사', 1, 'TASK'),\n",
        "    (10, True, 2, '기타', 1, 'TASK'),\n",
        "    (11, True, 2, '서울', 2, 'REGION'),\n",
        "    (12, True, 2, '경기', 2, 'REGION'),\n",
        "    (13, True, 2, '부산', 2, 'REGION'),\n",
        "    (14, True, 2, '경남', 2, 'REGION'),\n",
        "    (15, True, 2, '인천', 2, 'REGION'),\n",
        "    (16, True, 2, '경북', 2, 'REGION'),\n",
        "    (17, True, 2, '대구', 2, 'REGION'),\n",
        "    (18, True, 2, '충남', 2, 'REGION'),\n",
        "    (19, True, 2, '전남', 2, 'REGION'),\n",
        "    (20, True, 2, '전북특별자치도', 2, 'REGION'),\n",
        "    (21, True, 2, '충북', 2, 'REGION'),\n",
        "    (22, True, 2, '강원특별자치도', 2, 'REGION'),\n",
        "    (23, True, 2, '대전', 2, 'REGION'),\n",
        "    (24, True, 2, '광주', 2, 'REGION'),\n",
        "    (25, True, 2, '울산', 2, 'REGION'),\n",
        "    (26, True, 2, '제주특별자치도', 2, 'REGION'),\n",
        "    (27, True, 2, '세종특별자치시', 2, 'REGION')\n",
        "]\n",
        "\n",
        "# DataFrame으로 변환\n",
        "category_df = pd.DataFrame(category_data, columns=['id', 'enabled', 'level', 'name', 'parent_id', 'type'])\n",
        "\n",
        "# 지역코드 매핑\n",
        "region_code_map = {\n",
        "    \"서울\": 101,\n",
        "    \"경기\": 102,\n",
        "    \"부산\": 103,\n",
        "    \"경남\": 104,\n",
        "    \"인천\": 105,\n",
        "    \"경북\": 106,\n",
        "    \"대구\": 107,\n",
        "    \"충남\": 108,\n",
        "    \"전남\": 109,\n",
        "    \"전북특별자치도\": 110,\n",
        "    \"충북\": 111,\n",
        "    \"강원특별자치도\": 112,\n",
        "    \"대전\": 113,\n",
        "    \"광주\": 114,\n",
        "    \"울산\": 115,\n",
        "    \"제주특별자치도\": 116,\n",
        "    \"세종특별자치시\": 117\n",
        "}\n",
        "\n",
        "# job_types 정의\n",
        "job_types = {\n",
        "    \"일상 도움\": [\"강아지 산책\", \"강아지 발톱 정리\", \"고양이 귀청소\", \"햄스터 톱밥 청소\", \"화분 분갈이\", \"커튼봉 설치\", \"여행계획\", \"기차 예매\", \"쇼핑 같이\", \"전화 문의 대신\", \"찢어진 인형 수리\", \"그늘막 설치\", \"모루인형 만들기\", \"시험장까지 픽업\", \"아이 픽업\"],\n",
        "    \"정리 및 청소\": [\"정리정돈\", \"집 청소\", \"화단 청소\", \"이불 빨래\", \"베란다 창문 닦기\", \"대형 폐기물 운반\", \"현수막 수거\"],\n",
        "    \"물류 및 배송\": [\"배달\", \"짐 이동\", \"우편물\", \"헬스기구 운반\", \"가게에서 물건 픽업\", \"터미널 수화물 픽업\", \"굿즈 대리구매\", \"팝업스토어 대리구매\", \"과일포장 작업\", \"식품 포장\", \"준비물 전달\"],\n",
        "    \"기술 작업\": [\"정비\", \"침대 프레임 조립\", \"시계 약 교체\", \"커튼봉 설치\", \"싱크대 수전 교체\", \"워셔액 보충\", \"차량 와이퍼 교체\", \"컴퓨터 설치\", \"노트북 수리\", \"증명사진 보정\"],\n",
        "    \"매장\": [\"생일선물 포장\", \"포장\", \"전단지 부착\", \"홍보물부착\"],\n",
        "    \"사무 및 교육\": [\"미술학원 일일 보조 강사\", \"학원 수강생 출석 체크\", \"수업 자료 정리\"],\n",
        "    \"행사\": [\"체육대회 정리\", \"스타벅스 프리퀀시 수령 오픈런\", \"이벤트 장식 설치\"],\n",
        "    \"기타\": [\"단순조립\", \"헤어 모델\", \"고양이 방문 시터\", \"피아노 운반/조율\", \"유튜브 콘텐츠 촬영\", \"당근마켓 지역 인증\", \"벌집 제거\"]\n",
        "}\n",
        "\n",
        "# job_post_id와 title, location, region_code 추출\n",
        "job_posts = []\n",
        "\n",
        "with open('result/bulk_insert_job_post.sql', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if line.startswith('INSERT INTO') or not line:\n",
        "            continue\n",
        "        if line.endswith('),'):\n",
        "            line = line[:-1]  # ), 행의 마지막에 있는 쉼표 제거\n",
        "        line = line.strip('()')\n",
        "        parts = list(csv.reader([line], quotechar=\"'\", skipinitialspace=True))[0]\n",
        "\n",
        "        job_post_id = int(parts[0])\n",
        "        title = parts[12]\n",
        "        location = parts[11]\n",
        "        region_code = int(parts[14].strip(\");\"))  # 문자열에서 )와 ;를 제거\n",
        "        job_posts.append((job_post_id, title, location, region_code))\n",
        "\n",
        "# SQL 파일 오픈\n",
        "with open('result/bulk_insert_job_post_category.sql', 'w') as file:\n",
        "    # Bulk insert 시작 부분\n",
        "    file.write(\"INSERT INTO job_post_category (id, category_id, job_post_id) VALUES\\n\")\n",
        "\n",
        "    entry_id = 1\n",
        "    values = []\n",
        "\n",
        "    for job_post_id, title, location, region_code in job_posts:\n",
        "        # title에서 키워드가 포함된 TASK 카테고리 선택\n",
        "        task_category_added = False\n",
        "        for category, keywords in job_types.items():\n",
        "            if any(keyword in title for keyword in keywords):\n",
        "                task_category_id = category_df[category_df['name'] == category].iloc[0]['id']\n",
        "                values.append(f\"({entry_id}, {task_category_id}, {job_post_id})\")\n",
        "                entry_id += 1\n",
        "                task_category_added = True\n",
        "                break\n",
        "\n",
        "        if not task_category_added:\n",
        "            # 키워드가 없는 경우 TASK 카테고리를 '기타'로 설정\n",
        "            task_category_id = category_df[category_df['name'] == '기타'].iloc[0]['id']\n",
        "            values.append(f\"({entry_id}, {task_category_id}, {job_post_id})\")\n",
        "            entry_id += 1\n",
        "\n",
        "        # REGION 카테고리 추가\n",
        "        for region, code in region_code_map.items():\n",
        "            if code == region_code:\n",
        "                region_name = region\n",
        "                region_category_id = category_df[category_df['name'] == region_name].iloc[0]['id']\n",
        "                values.append(f\"({entry_id}, {region_category_id}, {job_post_id})\")\n",
        "                entry_id += 1\n",
        "                break\n",
        "\n",
        "    # 데이터 쓰기\n",
        "    file.write(\",\\n\".join(values) + \";\\n\")"
      ],
      "metadata": {
        "id": "0a3STsU6XcQb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}